---
title: "ENVS 193 DS week 7 workshop"
format: html
editor: visual
execute: 
  warning: false
  message: false
---

# Set up

```{r libraries}
library(tidyverse)
library(here)
library(lterdatasampler)

library(performance)
library(broom)
library(flextable)
library(ggeffects)
library(car)
library(naniar)
```


# Linear Models

How does stem length _predict_ stem dry mass?

```{r filtering-data}
maples_data <- hbr_maples %>% 
  filter(year == 2003 & watershed == "Reference")
```

Visualizing missing data:

```{r missing-data-vis}
gg_miss_var(maples_data)
```

Create an exploratory data visualization:

```{r explore-data-vis}
ggplot(data = maples_data, aes(x = stem_length, y = stem_dry_mass)) +
  geom_point()
```

Let's try a model:

```{r linear-model-maples}
maples_model <- lm(stem_dry_mass ~ stem_length, data = maples_data)

maples_model
```

Check assumptions:

1. linear relationship between variables: yes! (used exploratory data visualization to check that)
2. independence of errors: yes! (making that assumption based on how the data were collected)
3. homoskedasticity of errors: yes! (making that decision from residuals vs fitted plot/scale-location plots)
4. normally distributed errors: yes! (looking at QQ plot of residuals)

 residuals = difference between observed and expected values
 looking at residual plot, the residuals seem homoscedastic 
 looking at qqplot, the residuals look normally distributed (follow linear path)
 residuals vs leverage, not many outliers (if any) influencing model predictions

```{r checking-assumptions}
par(mfrow = c(2, 2))
plot(maples_model)
```

turn off the 2x2 grid:

```{r turning-off-the-grid, results = FALSE}
dev.off()
```

# Putting things together to communicate

## model predictions

```{r pulling-out-predictions}
predictions <- ggpredict(maples_model, terms = "stem_length")
# terms = what predictor was in the model
```

plot predictions:

```{r plotting-predictions}
plot_predictions <- ggplot(data = maples_data, aes(x = stem_length, y = stem_dry_mass)) +
  # first plot the underlying data
  geom_point() +
  # plotting model predictions from the "predictions" object from ggeffects
  geom_line(data = predictions, aes(x = x, y = predicted), color = "blue", linewidth = 1) +
  # plot the confidence interval around model estimates
  geom_ribbon(data = predictions, aes(x = x, y = predicted, ymin = conf.low, ymax = conf.high), alpha = 0.2)


plot_predictions
```

## create tables

```{r model-summary-table}
model_summary <- summary(maples_model)

model_squares <- anova(maples_model)

model_summary
```

making a table

```{r}
model_squares_table <- tidy(model_squares) %>% 
  mutate(p.value = case_when(
    p.value < 0.001 ~ "< 0.001"
  )) %>% 
  flextable() %>% 
  set_header_labels(df = "Degrees of freedom", 
                    sumsq = "Sum of squares")

model_squares_table
```








